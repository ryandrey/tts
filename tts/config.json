{
  "name": "default_config_fft_2",
  "n_gpu": 1,
  "arch": {
    "type": "FastSpeech",
    "args": {
      "ntoken": 51,
      "d_model": 384,
      "d_k": 384,
      "num_attn_layers": 2,
      "conv_d": 1536,
      "kernel_size": 3,
      "nlayers": 2,
      "num_mels": 80,
      "dropout": 0.1
    }
  },
  "data": {
    "train": {
      "batch_size": 8,
      "num_workers": 5,
      "datasets": [
        {
          "type": "LJSpeechDataset",
          "args": {
            "root": ".",
            "limit": 8
          }
        }
      ],
      "collator": {
        "type": "LJSpeechCollator",
        "args": {}
      }
    }
  },
  "optimizer": {
    "type": "Adam",
    "args": {
      "lr": 1e-3,
      "betas": [0.9, 0.98],
      "eps": 1e-9
    }
  },
  "mel_loss": {
    "type": "MelLoss",
    "args": {}
  },
  "dur_loss": {
    "type": "DurLoss",
    "arg": {}
  },
  "lr_scheduler": {
    "type": "OneCycleLR",
    "args": {
      "steps_per_epoch": 300,
      "epochs": 10,
      "anneal_strategy": "cos",
      "max_lr": 4e-3,
      "pct_start": 0.2
    }
  },
  "trainer": {
    "epochs": 50,
    "save_dir": "saved/",
    "save_period": 10,
    "verbosity": 2,
    "monitor": "min mel_loss",
    "early_stop": 100,
    "visualize": "wandb",
    "wandb_project": "tts_project",
    "len_epoch": 100,
    "grad_norm_clip": 10
  }
}
